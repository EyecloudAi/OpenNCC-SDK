(window.webpackJsonp=window.webpackJsonp||[]).push([[26],{382:function(_,v,t){"use strict";t.r(v);var e=t(44),d=Object(e.a)({},(function(){var _=this,v=_.$createElement,t=_._self._c||v;return t("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[t("h2",{attrs:{id:"概述"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#概述"}},[_._v("#")]),_._v(" 概述")]),_._v(" "),t("p",[_._v("OpenNCC View是一款用于快速体验OpenNCC开发套件的软件，运行OpenNCC View下默认模型不依赖OpenVINO，OpenNCC View集成了OpenNCC CDK全部API,可以完成OpenNCC在独立模式下实现对相机的连接,固件和AI模型的下载，及完成视频流显示与算法结果的后处理。用户可以通过友好的界面，来操作和控制相机."),t("br"),_._v(" "),t("img",{attrs:{src:"/openncc/docimg/zh/NccViewF1.png",alt:"Figure-1"}})]),_._v(" "),t("h2",{attrs:{id:"运行环境与安装"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#运行环境与安装"}},[_._v("#")]),_._v(" 运行环境与安装")]),_._v(" "),t("ul",[t("li",[_._v("操作系统：Ubuntu16.04(64 bit)、Ubuntu18.04 (64 bit)")]),_._v(" "),t("li",[_._v("编译环境：QT 5.9.9及以上")])]),_._v(" "),t("h3",{attrs:{id:"qt安装"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#qt安装"}},[_._v("#")]),_._v(" QT安装")]),_._v(" "),t("p",[t("a",{attrs:{href:"http://download.qt.io/archive/qt/",target:"_blank",rel:"noopener noreferrer"}},[_._v("QT下载地址"),t("OutboundLink")],1),t("br"),_._v("\n开发所用版本为QT5.12.7，尽量保持一致。下载linux安装包后，添加可执行权限，然后运行。"),t("br"),_._v("\n安装按默认路径即可，断网安装不用登陆账号，否则需要注册验证后完成安装。"),t("br"),_._v("\nQT安装完成后运行简单的例子，如果编译会出现"),t("code",[_._v('"cannot find -lGL"')]),_._v("错误："),t("br"),_._v("\n可以使用"),t("code",[_._v("locate libGL*")]),_._v("查找"),t("code",[_._v("libGL.so")]),_._v("文件，再用管理员权限添加软链接，链接到/usr/lib目录"),t("code",[_._v("locate libGL*")]),_._v("，\n"),t("code",[_._v("sudo ln -s /usr/lib/xxx/libGL.so.1 /usr/lib/libGL.so")])]),_._v(" "),t("h3",{attrs:{id:"安装依赖包"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#安装依赖包"}},[_._v("#")]),_._v(" 安装依赖包")]),_._v(" "),t("ul",[t("li",[_._v("OpenCV"),t("br"),_._v(" "),t("code",[_._v("sudo apt-get update")]),t("br"),_._v(" "),t("code",[_._v("sudo apt-get install libcv-dev")]),t("br"),_._v(" "),t("code",[_._v("sudo apt-get install libopencv-dev")])]),_._v(" "),t("li",[_._v("安装libsub1.0"),t("br"),_._v(" "),t("code",[_._v("sudo apt-get install libusb-dev")]),t("br"),_._v(" "),t("code",[_._v("sudo apt-get install libusb-1.0-0-dev")])]),_._v(" "),t("li",[_._v("安装ffmpeg"),t("br"),_._v(" "),t("code",[_._v("sudo apt-get install ffmpeg")])])]),_._v(" "),t("h3",{attrs:{id:"编译view工程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#编译view工程"}},[_._v("#")]),_._v(" 编译View工程")]),_._v(" "),t("ol",[t("li",[_._v("使用Qt Creator打开"),t("code",[_._v("View/Linux/OpenNCC/OpenNCC")]),_._v("的"),t("code",[_._v("OpenNCC.pro")]),_._v("工程")]),_._v(" "),t("li",[_._v("编译工程")]),_._v(" "),t("li",[_._v("将"),t("code",[_._v("View/Linux/OpenNCC/Configuration")]),_._v("目录拷贝到编译运行目录下，如"),t("code",[_._v("build-OpenNCC-Desktop_Qt_5_12_7_GCC_64bit-Debug")])]),_._v(" "),t("li",[_._v("开始调试、运行程序")])]),_._v(" "),t("h2",{attrs:{id:"运行与功能"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#运行与功能"}},[_._v("#")]),_._v(" 运行与功能")]),_._v(" "),t("h3",{attrs:{id:"_1-openncc相机运行权限"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-openncc相机运行权限"}},[_._v("#")]),_._v(" 1. OpenNCC相机运行权限")]),_._v(" "),t("p",[_._v("请进入CDK目录：Tools/deployment下，运行脚本“install_NCC_udev_rules.sh”，在终端下输入："),t("br"),_._v("\n./install_NCC_udev_rules.sh"),t("br"),_._v("\n获取相机挂载权限,成功后需要重启电脑。"),t("br"),_._v(" "),t("img",{attrs:{src:"/openncc/docimg/zh/GettingStartF2.png",alt:"Figure-2"}})]),_._v(" "),t("h3",{attrs:{id:"_2-解压openncc-view软件-进入目录下-打开终端-输入"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-解压openncc-view软件-进入目录下-打开终端-输入"}},[_._v("#")]),_._v(" 2. 解压OpenNCC View软件，进入目录下，打开终端，输入：")]),_._v(" "),t("p",[t("code",[_._v("./AppRun")]),_._v("，启动软件。（如果无法运行，输入:"),t("code",[_._v("sudo ./AppRun")]),_._v("再次尝试 ）"),t("br"),_._v("\nOpenNCC View软件成功启动后，接下来可以操作实现相机和View之间的交互，操作步骤："),t("br"),_._v("\n* 在前面的操作步骤中已经把View基本的功能都解释清楚了，还有一部分操作就增加了在这里"),t("br"),_._v("\n1."),t("code",[_._v("Get device info")]),_._v("，用来获取设备。"),t("br"),_._v("\n2.在"),t("code",[_._v("Stream Format")]),_._v("中选择你要的格式，USB3.0一共四种(yuv420p,H.264,H.265,MJPG)"),t("br"),_._v("\n3.在"),t("code",[_._v("Stream Resolution")]),_._v("中，可以选择"),t("code",[_._v("1080P 30")]),_._v("和"),t("code",[_._v("4K 30")]),_._v("。"),t("br"),_._v("\n4.在"),t("code",[_._v("1st net work model")]),_._v("的选择时候，可以考虑是否要算法加速，需要的话可以勾选"),t("code",[_._v("inference accelerate")]),_._v("，这个必须在选择模型前勾选。模型你可以选择自带的，也可以自己加model进来，从下面的图可以看出原本只有10个model，现在通过View上的"),t("code",[_._v("Add model")]),_._v("将本地model加入进来。"),t("br"),_._v(" "),t("img",{attrs:{src:"/openncc/docimg/zh/view_model.png",alt:"Figure-3"}}),_._v(" "),t("img",{attrs:{src:"/openncc/docimg/zh/view_model2.png",alt:"Figure-3"}}),_._v("\n选择完要加在的model，然后"),t("code",[_._v("Confirm")]),_._v("，成功的话会提示"),t("code",[_._v("Success")]),_._v("。"),t("br"),_._v("\n二级模型可以看前面操作步骤2.1的二级模型演示。"),t("br"),_._v("\n5.选择好model后，你可以在"),t("code",[_._v("Region of interset for model")]),_._v("中画出你需要的有效区域，也就是你下图看到的NCC ROI红色边框的那个区域。"),t("br"),_._v("\n6.如果你需要的话可以调整"),t("code",[_._v("Model Score")]),_._v("和"),t("code",[_._v("Display Scaler")]),_._v("，第一个是算法识别最低分数，第二个是视频显示窗体大小。"),t("br"),_._v("\n7.可以选择曝光"),t("code",[_._v("Exposure control")]),_._v("是自动(Auto)还是手动(Manual)。"),t("br"),_._v("\n8.如果想把视频的当前状态显示到视频中，可以勾选"),t("code",[_._v("show state")]),_._v("，需要保存视频的话可以勾选"),t("code",[_._v("save_avi")]),_._v("，"),t("code",[_._v("save_avi")]),_._v("在yuv420p下是没有的。"),t("br"),_._v("\n9.最后可以"),t("code",[_._v("Start running model")]),_._v("了。"),t("br"),_._v("\n运行视频流，加载人脸检测算法成功后实拍截图："),t("br"),_._v(" "),t("img",{attrs:{src:"/openncc/docimg/zh/face-detection.png",alt:"Figure-3"}})]),_._v(" "),t("h3",{attrs:{id:"_3-模型解析"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-模型解析"}},[_._v("#")]),_._v(" 3. 模型解析")]),_._v(" "),t("p",[_._v("模型在OpenNCC完成推演后，通过OpenNCC CDK API获取实时的推演结果，OpenView针对物体检测这类模型"),t("a",{attrs:{href:"https://docs.openvinotoolkit.org/2019_R1.1/usergroup1.html",target:"_blank",rel:"noopener noreferrer"}},[_._v("Object Detection Models"),t("OutboundLink")],1),_._v("实现了推演结果的通用解析器。"),t("br"),_._v("\nOpenView的推演后处理支持如下格式输出：")]),_._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[_._v("输出的数据形态：[1, 1, N, 7]\nN是当前帧下检测到的物体框数量\n对于每个检测框，包含以下信息格式：[image_id, label, conf, x_min, y_min, x_max, y_max], 其中:\n    image_id - ID of the image in the batch\n    label - predicted class ID\n    conf - confidence for the predicted class\n    (x_min, y_min) - coordinates of the top left bounding box corner\n    (x_max, y_max) - coordinates of the bottom right bounding box corner.  \n")])])]),t("p",[_._v("用户可以训练自己的模型，并将输出层按照以上格式定义，可以免编程使用OpenView的模型导入功能添加并测试物体检测模型。如果用户需要添加其他输出格式的模型，需要自己参考ncc_cdk/Samples/How_to/load a model并结合自己应用场景来编写解析代码。")]),_._v(" "),t("h3",{attrs:{id:"_4-功能点详细介绍"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-功能点详细介绍"}},[_._v("#")]),_._v(" 4. 功能点详细介绍")]),_._v(" "),t("p",[_._v("1）Get Device Info：获取设备与电脑usb连接信息及NCC设备模块信息，若连接的设备支持，能够解锁更多功能选项。（例如NCC与电脑通过usb 3.0连接，可解锁yuv出流显示视频；NCC装配了4K模组，可解锁4K分辨率显示）")]),_._v(" "),t("p",[_._v("2）Stream Format：选择NCC相机USB视频输出格式，目前支持YUV420P，H.264，MJPEG格式。（选择YUV420P前需先点击Get Device Info，仅在usb 3.0连接时可选）")]),_._v(" "),t("p",[_._v("3）Stream Resolution：更换NCC相机的视频分辨率，可选1080P或4K. 4K分辨率支持需要选装相应4K摄像模块。 （选择4K前需先Get Device Info，仅在模组支持4K时可选）")]),_._v(" "),t("p",[_._v("4）1st network model：选择算法模型，选择None即不加载模型，仅出流显示视频，而选择加载算法模型后，可以通过框选ROI区域，仅对区域内的场景进行识别。")]),_._v(" "),t("p",[_._v("5）Model Score：加载算法后，对物品的识别计算结果是有分数的，当超过了某一分数阈值，才会在视频中框选，而Model Score即为控制阈值的选项，根据用户需求，实时调整识别的最低分数（默认值为0.5）")]),_._v(" "),t("p",[_._v("6）ROI：配合算法模型使用，加载模型后，如果需要仅对某一区域进行算法识别，可以手动点击鼠标左键拖动，框选出自己感兴趣的区域，仅对区域内的场景进行识别")]),_._v(" "),t("p",[_._v("7）Display Scaler：视频显示时，由于不同电脑的分辨率不同，按原本尺寸显示1080P或4K的视频，可能会出现视频大小超出桌面大小的情况，用户可通过Display Scaler实时控制视频显示窗体大小（默认值为0.5）")]),_._v(" "),t("p",[_._v('8）Add model：点击"add model"  ，导入生成好的.blob模型文件，此处注意，需要把.blob文件和对应的IR文件(.xml&&.bin)放在同一位置，且文件名相同。.blob文件的生成过程参考开发手册。添加后即可在1st network model中选择对应模型。')]),_._v(" "),t("p",[_._v("9）Del model：删除用户导入的模型文件，删除后即会在1st network model中移除用户自己的模型。")]),_._v(" "),t("p",[_._v("10）Start running model：点击即开始加载固件，并根据用户的选项，显示视频窗口")]),_._v(" "),t("p",[_._v("11）Log：显示NCC工作时的log，用户可在此处查看设备的运行状况，以及关于设备异常状态的提示信息")]),_._v(" "),t("p",[_._v("12）Algo Results：显示算法结果，当用户选择加载算法模型，且在实际场景中有被识别到的算法模型，即会有算法结果在此处打印（如被识别模型相对当前窗口的坐标信息，及算法计算出的识别分数等）")]),_._v(" "),t("h3",{attrs:{id:"_5-固件算法加速测试"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-固件算法加速测试"}},[_._v("#")]),_._v(" 5. 固件算法加速测试")]),_._v(" "),t("table",[t("thead",[t("tr",[t("th",[_._v("版本信息")]),_._v(" "),t("th",[_._v("60Hz")]),_._v(" "),t("th",[_._v("YUV")]),_._v(" "),t("th"),_._v(" "),t("th"),_._v(" "),t("th"),_._v(" "),t("th",[_._v("H.264")]),_._v(" "),t("th",[_._v("H.264")]),_._v(" "),t("th"),_._v(" "),t("th"),_._v(" "),t("th",[_._v("MJPEG")]),_._v(" "),t("th",[_._v("MJPEG")]),_._v(" "),t("th"),_._v(" "),t("th")])]),_._v(" "),t("tbody",[t("tr",[t("td"),_._v(" "),t("td",[_._v("1080P  3.0usb")]),_._v(" "),t("td",[_._v("双引擎")]),_._v(" "),t("td"),_._v(" "),t("td",[_._v("单引擎")]),_._v(" "),t("td"),_._v(" "),t("td",[_._v("双引擎")]),_._v(" "),t("td"),_._v(" "),t("td",[_._v("单引擎")]),_._v(" "),t("td"),_._v(" "),t("td",[_._v("双引擎")]),_._v(" "),t("td"),_._v(" "),t("td",[_._v("单引擎")]),_._v(" "),t("td")]),_._v(" "),t("tr",[t("td"),_._v(" "),t("td",[_._v("模型")]),_._v(" "),t("td",[_._v("传输帧率")]),_._v(" "),t("td",[_._v("AI FPS")]),_._v(" "),t("td",[_._v("传输帧率")]),_._v(" "),t("td",[_._v("AI FPS")]),_._v(" "),t("td",[_._v("传输帧率")]),_._v(" "),t("td",[_._v("AI FPS")]),_._v(" "),t("td",[_._v("传输帧率")]),_._v(" "),t("td",[_._v("AI FPS")]),_._v(" "),t("td",[_._v("传输帧率")]),_._v(" "),t("td",[_._v("AI FPS")]),_._v(" "),t("td",[_._v("传输帧率")]),_._v(" "),t("td",[_._v("AI FPS")])]),_._v(" "),t("tr",[t("td"),_._v(" "),t("td",[_._v("classification-fp16")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("14")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("14")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("14")]),_._v(" "),t("td")]),_._v(" "),t("tr",[t("td"),_._v(" "),t("td",[_._v("face-detection-retail-0004-fp16")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("55")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("55")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("52")]),_._v(" "),t("td")]),_._v(" "),t("tr",[t("td"),_._v(" "),t("td",[_._v("face-detection-adas-0001-fp16")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("8")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("8")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("8")]),_._v(" "),t("td")]),_._v(" "),t("tr",[t("td"),_._v(" "),t("td",[_._v("person-detection-retail-0013-fp16")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("6")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("6")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("6")]),_._v(" "),t("td")]),_._v(" "),t("tr",[t("td"),_._v(" "),t("td",[_._v("person-vehicle-bike-detection-crossroad-0078-fp16")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("2")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("3")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("3")]),_._v(" "),t("td")]),_._v(" "),t("tr",[t("td"),_._v(" "),t("td",[_._v("face-person-detection-retail-0002-fp16")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("5")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("5")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("5")]),_._v(" "),t("td")]),_._v(" "),t("tr",[t("td"),_._v(" "),t("td",[_._v("pedestrian-detection-adas-0002-fp16")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("8")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("9")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("9")]),_._v(" "),t("td")]),_._v(" "),t("tr",[t("td"),_._v(" "),t("td",[_._v("vehicle-detection-adas-0002-fp16")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("9")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("9")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("9")]),_._v(" "),t("td")]),_._v(" "),t("tr",[t("td"),_._v(" "),t("td",[_._v("vehicle-license-plate-detection-barrier-0106-fp16")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("28")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("28")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("29")]),_._v(" "),t("td")]),_._v(" "),t("tr",[t("td"),_._v(" "),t("td",[_._v("--license-plate-recognition-barrier-0001")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("23")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("23")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("23")]),_._v(" "),t("td")]),_._v(" "),t("tr",[t("td"),_._v(" "),t("td",[_._v("pedestrian-and-vehicle-detector-adas-0001-fp16")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("7")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("7")]),_._v(" "),t("td"),_._v(" "),t("td"),_._v(" "),t("td",[_._v("7")]),_._v(" "),t("td")])])])])}),[],!1,null,null,null);v.default=d.exports}}]);